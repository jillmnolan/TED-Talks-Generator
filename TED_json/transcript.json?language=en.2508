{"paragraphs":[{"cues":[{"time":760,"text":"So when people voice fears\nof artificial intelligence,"},{"time":4320,"text":"very often, they invoke images\nof humanoid robots run amok."},{"time":8320,"text":"You know? Terminator?"},{"time":10400,"text":"You know, that might be\nsomething to consider,"},{"time":12760,"text":"but that's a distant threat."},{"time":14640,"text":"Or, we fret about digital surveillance"},{"time":18120,"text":"with metaphors from the past."},{"time":19920,"text":"\"1984,\" George Orwell's \"1984,\""},{"time":22600,"text":"it's hitting the bestseller lists again."},{"time":25960,"text":"It's a great book,"},{"time":27400,"text":"but it's not the correct dystopia\nfor the 21st century."},{"time":32080,"text":"What we need to fear most"},{"time":33520,"text":"is not what artificial intelligence\nwill do to us on its own,"},{"time":38320,"text":"but how the people in power\nwill use artificial intelligence"},{"time":43080,"text":"to control us and to manipulate us"},{"time":45920,"text":"in novel, sometimes hidden,"},{"time":49080,"text":"subtle and unexpected ways."},{"time":52120,"text":"Much of the technology"},{"time":54000,"text":"that threatens our freedom\nand our dignity in the near-term future"},{"time":58360,"text":"is being developed by companies"},{"time":60240,"text":"in the business of capturing\nand selling our data and our attention"},{"time":65200,"text":"to advertisers and others:"},{"time":67480,"text":"Facebook, Google, Amazon,"},{"time":70920,"text":"Alibaba, Tencent."}]},{"cues":[{"time":74040,"text":"Now, artificial intelligence has started\nbolstering their business as well."},{"time":79560,"text":"And it may seem\nlike artificial intelligence"},{"time":81680,"text":"is just the next thing after online ads."},{"time":84560,"text":"It's not."},{"time":85800,"text":"It's a jump in category."},{"time":88280,"text":"It's a whole different world,"},{"time":90880,"text":"and it has great potential."},{"time":93520,"text":"It could accelerate our understanding\nof many areas of study and research."},{"time":101120,"text":"But to paraphrase\na famous Hollywood philosopher,"},{"time":104640,"text":"\"With prodigious potential\ncomes prodigious risk.\""}]},{"cues":[{"time":109120,"text":"Now let's look at a basic fact\nof our digital lives, online ads."},{"time":113080,"text":"Right? We kind of dismiss them."},{"time":116000,"text":"They seem crude, ineffective."},{"time":118000,"text":"We've all had the experience\nof being followed on the web"},{"time":122280,"text":"by an ad based on something\nwe searched or read."},{"time":125080,"text":"You know, you look up a pair of boots"},{"time":126960,"text":"and for a week, those boots are following\nyou around everywhere you go."},{"time":130360,"text":"Even after you succumb and buy them,\nthey're still following you around."},{"time":134040,"text":"We're kind of inured to that kind\nof basic, cheap manipulation."},{"time":137080,"text":"We roll our eyes and we think,\n\"You know what? These things don't work.\""},{"time":141720,"text":"Except, online,"},{"time":143840,"text":"the digital technologies are not just ads."},{"time":148240,"text":"Now, to understand that,\nlet's think of a physical world example."},{"time":151840,"text":"You know how, at the checkout counters\nat supermarkets, near the cashier,"},{"time":156520,"text":"there's candy and gum\nat the eye level of kids?"},{"time":160800,"text":"That's designed to make them\nwhine at their parents"},{"time":164320,"text":"just as the parents\nare about to sort of check out."},{"time":168040,"text":"Now, that's a persuasion architecture."},{"time":171160,"text":"It's not nice, but it kind of works."},{"time":174280,"text":"That's why you see it\nin every supermarket."},{"time":176720,"text":"Now, in the physical world,"},{"time":178440,"text":"such persuasion architectures\nare kind of limited,"},{"time":180960,"text":"because you can only put\nso many things by the cashier. Right?"},{"time":185800,"text":"And the candy and gum,\nit's the same for everyone,"},{"time":190120,"text":"even though it mostly works"},{"time":191600,"text":"only for people who have\nwhiny little humans beside them."},{"time":197160,"text":"In the physical world,\nwe live with those limitations."}]},{"cues":[{"time":202280,"text":"In the digital world, though,"},{"time":204240,"text":"persuasion architectures\ncan be built at the scale of billions"},{"time":209840,"text":"and they can target, infer, understand"},{"time":213720,"text":"and be deployed at individuals"},{"time":216640,"text":"one by one"},{"time":217880,"text":"by figuring out your weaknesses,"},{"time":220040,"text":"and they can be sent\nto everyone's phone private screen,"},{"time":225680,"text":"so it's not visible to us."},{"time":227960,"text":"And that's different."},{"time":229240,"text":"And that's just one of the basic things\nthat artificial intelligence can do."}]},{"cues":[{"time":232840,"text":"Now, let's take an example."},{"time":234200,"text":"Let's say you want to sell\nplane tickets to Vegas. Right?"},{"time":236920,"text":"So in the old world, you could think\nof some demographics to target"},{"time":240440,"text":"based on experience\nand what you can guess."},{"time":243560,"text":"You might try to advertise to, oh,"},{"time":246400,"text":"men between the ages of 25 and 35,"},{"time":248920,"text":"or people who have\na high limit on their credit card,"},{"time":252880,"text":"or retired couples. Right?"},{"time":254280,"text":"That's what you would do in the past."}]},{"cues":[{"time":256120,"text":"With big data and machine learning,"},{"time":259040,"text":"that's not how it works anymore."},{"time":261320,"text":"So to imagine that,"},{"time":263520,"text":"think of all the data\nthat Facebook has on you:"},{"time":267400,"text":"every status update you ever typed,"},{"time":269960,"text":"every Messenger conversation,"},{"time":272000,"text":"every place you logged in from,"},{"time":276400,"text":"all your photographs\nthat you uploaded there."},{"time":279600,"text":"If you start typing something\nand change your mind and delete it,"},{"time":283400,"text":"Facebook keeps those\nand analyzes them, too."},{"time":287160,"text":"Increasingly, it tries\nto match you with your offline data."},{"time":291120,"text":"It also purchases\na lot of data from data brokers."},{"time":294320,"text":"It could be everything\nfrom your financial records"},{"time":297760,"text":"to a good chunk of your browsing history."},{"time":300360,"text":"Right? In the US,\nsuch data is routinely collected,"},{"time":305800,"text":"collated and sold."},{"time":308320,"text":"In Europe, they have tougher rules."}]},{"cues":[{"time":311680,"text":"So what happens then is,"},{"time":314920,"text":"by churning through all that data,\nthese machine-learning algorithms --"},{"time":318960,"text":"that's why they're called\nlearning algorithms --"},{"time":321880,"text":"they learn to understand\nthe characteristics of people"},{"time":326000,"text":"who purchased tickets to Vegas before."},{"time":329760,"text":"When they learn this from existing data,"},{"time":333320,"text":"they also learn\nhow to apply this to new people."},{"time":337160,"text":"So if they're presented with a new person,"},{"time":340240,"text":"they can classify whether that person\nis likely to buy a ticket to Vegas or not."},{"time":345720,"text":"Fine. You're thinking,\nan offer to buy tickets to Vegas."},{"time":351200,"text":"I can ignore that."},{"time":352680,"text":"But the problem isn't that."},{"time":354920,"text":"The problem is,"},{"time":356520,"text":"we no longer really understand\nhow these complex algorithms work."},{"time":360680,"text":"We don't understand\nhow they're doing this categorization."},{"time":364160,"text":"It's giant matrices,\nthousands of rows and columns,"},{"time":368600,"text":"maybe millions of rows and columns,"},{"time":371320,"text":"and not the programmers"},{"time":374760,"text":"and not anybody who looks at it,"},{"time":377440,"text":"even if you have all the data,"},{"time":378960,"text":"understands anymore\nhow exactly it's operating"},{"time":383600,"text":"any more than you'd know\nwhat I was thinking right now"},{"time":387400,"text":"if you were shown\na cross section of my brain."},{"time":392360,"text":"It's like we're not programming anymore,"},{"time":394960,"text":"we're growing intelligence\nthat we don't truly understand."}]},{"cues":[{"time":400520,"text":"And these things only work\nif there's an enormous amount of data,"},{"time":404520,"text":"so they also encourage\ndeep surveillance on all of us"},{"time":409640,"text":"so that the machine learning\nalgorithms can work."},{"time":412000,"text":"That's why Facebook wants\nto collect all the data it can about you."},{"time":415200,"text":"The algorithms work better."}]},{"cues":[{"time":416800,"text":"So let's push that Vegas example a bit."},{"time":419520,"text":"What if the system\nthat we do not understand"},{"time":424200,"text":"was picking up that it's easier\nto sell Vegas tickets"},{"time":429360,"text":"to people who are bipolar\nand about to enter the manic phase."},{"time":433640,"text":"Such people tend to become\noverspenders, compulsive gamblers."},{"time":439280,"text":"They could do this, and you'd have no clue\nthat's what they were picking up on."},{"time":443760,"text":"I gave this example\nto a bunch of computer scientists once"},{"time":447400,"text":"and afterwards, one of them came up to me."},{"time":449480,"text":"He was troubled and he said,\n\"That's why I couldn't publish it.\""},{"time":453600,"text":"I was like, \"Couldn't publish what?\""},{"time":455800,"text":"He had tried to see whether you can indeed\nfigure out the onset of mania"},{"time":461680,"text":"from social media posts\nbefore clinical symptoms,"},{"time":464920,"text":"and it had worked,"},{"time":466720,"text":"and it had worked very well,"},{"time":468800,"text":"and he had no idea how it worked\nor what it was picking up on."}]},{"cues":[{"time":474840,"text":"Now, the problem isn't solved\nif he doesn't publish it,"},{"time":479280,"text":"because there are already companies"},{"time":481200,"text":"that are developing\nthis kind of technology,"},{"time":483760,"text":"and a lot of the stuff\nis just off the shelf."},{"time":487240,"text":"This is not very difficult anymore."}]},{"cues":[{"time":489840,"text":"Do you ever go on YouTube\nmeaning to watch one video"},{"time":493320,"text":"and an hour later you've watched 27?"},{"time":496760,"text":"You know how YouTube\nhas this column on the right"},{"time":499280,"text":"that says, \"Up next\""},{"time":501520,"text":"and it autoplays something?"},{"time":503360,"text":"It's an algorithm"},{"time":504600,"text":"picking what it thinks\nthat you might be interested in"},{"time":508240,"text":"and maybe not find on your own."},{"time":509800,"text":"It's not a human editor."},{"time":511080,"text":"It's what algorithms do."},{"time":512520,"text":"It picks up on what you have watched\nand what people like you have watched,"},{"time":517280,"text":"and infers that that must be\nwhat you're interested in,"},{"time":521520,"text":"what you want more of,"},{"time":522799,"text":"and just shows you more."},{"time":524159,"text":"It sounds like a benign\nand useful feature,"},{"time":527280,"text":"except when it isn't."}]},{"cues":[{"time":529640,"text":"So in 2016, I attended rallies\nof then-candidate Donald Trump"},{"time":537840,"text":"to study as a scholar\nthe movement supporting him."},{"time":541200,"text":"I study social movements,\nso I was studying it, too."},{"time":544680,"text":"And then I wanted to write something\nabout one of his rallies,"},{"time":548040,"text":"so I watched it a few times on YouTube."},{"time":551240,"text":"YouTube started recommending to me"},{"time":554360,"text":"and autoplaying to me\nwhite supremacist videos"},{"time":558640,"text":"in increasing order of extremism."},{"time":561320,"text":"If I watched one,"},{"time":563160,"text":"it served up one even more extreme"},{"time":566160,"text":"and autoplayed that one, too."},{"time":568320,"text":"If you watch Hillary Clinton\nor Bernie Sanders content,"},{"time":572880,"text":"YouTube recommends\nand autoplays conspiracy left,"},{"time":577600,"text":"and it goes downhill from there."}]},{"cues":[{"time":580480,"text":"Well, you might be thinking,\nthis is politics, but it's not."},{"time":583560,"text":"This isn't about politics."},{"time":584840,"text":"This is just the algorithm\nfiguring out human behavior."},{"time":587960,"text":"I once watched a video\nabout vegetarianism on YouTube"},{"time":592760,"text":"and YouTube recommended\nand autoplayed a video about being vegan."},{"time":597720,"text":"It's like you're never\nhardcore enough for YouTube."}]},{"cues":[{"time":600760,"text":"(Laughter)"}]},{"cues":[{"time":602360,"text":"So what's going on?"},{"time":604520,"text":"Now, YouTube's algorithm is proprietary,"},{"time":608080,"text":"but here's what I think is going on."},{"time":611360,"text":"The algorithm has figured out"},{"time":613480,"text":"that if you can entice people"},{"time":617200,"text":"into thinking that you can\nshow them something more hardcore,"},{"time":620960,"text":"they're more likely to stay on the site"},{"time":623400,"text":"watching video after video\ngoing down that rabbit hole"},{"time":627840,"text":"while Google serves them ads."},{"time":631760,"text":"Now, with nobody minding\nthe ethics of the store,"},{"time":635720,"text":"these sites can profile people"},{"time":641680,"text":"who are Jew haters,"},{"time":644360,"text":"who think that Jews are parasites"},{"time":648320,"text":"and who have such explicit\nanti-Semitic content,"},{"time":654080,"text":"and let you target them with ads."},{"time":657200,"text":"They can also mobilize algorithms"},{"time":660760,"text":"to find for you look-alike audiences,"},{"time":663920,"text":"people who do not have such explicit\nanti-Semitic content on their profile"},{"time":669520,"text":"but who the algorithm detects\nmay be susceptible to such messages,"},{"time":675720,"text":"and lets you target them with ads, too."},{"time":678680,"text":"Now, this may sound\nlike an implausible example,"},{"time":681440,"text":"but this is real."},{"time":683480,"text":"ProPublica investigated this"},{"time":685640,"text":"and found that you can indeed\ndo this on Facebook,"},{"time":689280,"text":"and Facebook helpfully\noffered up suggestions"},{"time":691720,"text":"on how to broaden that audience."},{"time":694720,"text":"BuzzFeed tried it for Google,\nand very quickly they found,"},{"time":697760,"text":"yep, you can do it on Google, too."},{"time":699520,"text":"And it wasn't even expensive."},{"time":701240,"text":"The ProPublica reporter\nspent about 30 dollars"},{"time":705680,"text":"to target this category."}]},{"cues":[{"time":710600,"text":"So last year, Donald Trump's\nsocial media manager disclosed"},{"time":715920,"text":"that they were using Facebook dark posts\nto demobilize people,"},{"time":721280,"text":"not to persuade them,"},{"time":722680,"text":"but to convince them not to vote at all."},{"time":726520,"text":"And to do that,\nthey targeted specifically,"},{"time":730120,"text":"for example, African-American men\nin key cities like Philadelphia,"},{"time":734040,"text":"and I'm going to read\nexactly what he said."},{"time":736520,"text":"I'm quoting."}]},{"cues":[{"time":737760,"text":"They were using \"nonpublic posts"},{"time":740800,"text":"whose viewership the campaign controls"},{"time":743000,"text":"so that only the people\nwe want to see it see it."},{"time":746800,"text":"We modeled this."},{"time":748040,"text":"It will dramatically affect her ability\nto turn these people out.\""}]},{"cues":[{"time":753720,"text":"What's in those dark posts?"},{"time":756480,"text":"We have no idea."},{"time":758160,"text":"Facebook won't tell us."}]},{"cues":[{"time":760480,"text":"So Facebook also algorithmically\narranges the posts"},{"time":764880,"text":"that your friends put on Facebook,\nor the pages you follow."},{"time":768640,"text":"It doesn't show you\neverything chronologically."},{"time":770880,"text":"It puts the order in the way\nthat the algorithm thinks will entice you"},{"time":775720,"text":"to stay on the site longer."}]},{"cues":[{"time":779040,"text":"Now, so this has a lot of consequences."},{"time":782440,"text":"You may be thinking\nsomebody is snubbing you on Facebook."},{"time":786800,"text":"The algorithm may never\nbe showing your post to them."},{"time":790080,"text":"The algorithm is prioritizing\nsome of them and burying the others."}]},{"cues":[{"time":797320,"text":"Experiments show"},{"time":798640,"text":"that what the algorithm picks to show you\ncan affect your emotions."},{"time":804600,"text":"But that's not all."},{"time":806280,"text":"It also affects political behavior."},{"time":809360,"text":"So in 2010, in the midterm elections,"},{"time":814040,"text":"Facebook did an experiment\non 61 million people in the US"},{"time":819960,"text":"that was disclosed after the fact."},{"time":821880,"text":"So some people were shown,\n\"Today is election day,\""},{"time":825320,"text":"the simpler one,"},{"time":826720,"text":"and some people were shown\nthe one with that tiny tweak"},{"time":830640,"text":"with those little thumbnails"},{"time":832760,"text":"of your friends who clicked on \"I voted.\""},{"time":837000,"text":"This simple tweak."},{"time":839520,"text":"OK? So the pictures were the only change,"},{"time":843840,"text":"and that post shown just once"},{"time":847120,"text":"turned out an additional 340,000 voters"},{"time":853200,"text":"in that election,"},{"time":854920,"text":"according to this research"},{"time":856640,"text":"as confirmed by the voter rolls."},{"time":860920,"text":"A fluke? No."},{"time":862600,"text":"Because in 2012,\nthey repeated the same experiment."},{"time":868840,"text":"And that time,"},{"time":870600,"text":"that civic message shown just once"},{"time":873920,"text":"turned out an additional 270,000 voters."},{"time":879160,"text":"For reference, the 2016\nUS presidential election"},{"time":884400,"text":"was decided by about 100,000 votes."},{"time":889360,"text":"Now, Facebook can also\nvery easily infer what your politics are,"},{"time":894120,"text":"even if you've never\ndisclosed them on the site."},{"time":896400,"text":"Right? These algorithms\ncan do that quite easily."},{"time":899960,"text":"What if a platform with that kind of power"},{"time":903880,"text":"decides to turn out supporters\nof one candidate over the other?"},{"time":909680,"text":"How would we even know about it?"}]},{"cues":[{"time":913560,"text":"Now, we started from someplace\nseemingly innocuous --"},{"time":917720,"text":"online adds following us around --"},{"time":919960,"text":"and we've landed someplace else."},{"time":923480,"text":"As a public and as citizens,"},{"time":925960,"text":"we no longer know\nif we're seeing the same information"},{"time":929400,"text":"or what anybody else is seeing,"},{"time":931680,"text":"and without a common basis of information,"},{"time":934280,"text":"little by little,"},{"time":935920,"text":"public debate is becoming impossible,"},{"time":939160,"text":"and we're just at\nthe beginning stages of this."},{"time":942160,"text":"These algorithms can quite easily infer"},{"time":945640,"text":"things like your people's ethnicity,"},{"time":948920,"text":"religious and political views,\npersonality traits,"},{"time":951280,"text":"intelligence, happiness,\nuse of addictive substances,"},{"time":954680,"text":"parental separation, age and genders,"},{"time":957840,"text":"just from Facebook likes."},{"time":961440,"text":"These algorithms can identify protesters"},{"time":965520,"text":"even if their faces\nare partially concealed."},{"time":969720,"text":"These algorithms may be able\nto detect people's sexual orientation"},{"time":976360,"text":"just from their dating profile pictures."}]},{"cues":[{"time":981560,"text":"Now, these are probabilistic guesses,"},{"time":984200,"text":"so they're not going\nto be 100 percent right,"},{"time":987120,"text":"but I don't see the powerful resisting\nthe temptation to use these technologies"},{"time":992040,"text":"just because there are\nsome false positives,"},{"time":994240,"text":"which will of course create\na whole other layer of problems."},{"time":997520,"text":"Imagine what a state can do"},{"time":1000480,"text":"with the immense amount of data\nit has on its citizens."},{"time":1004680,"text":"China is already using\nface detection technology"},{"time":1009480,"text":"to identify and arrest people."},{"time":1013280,"text":"And here's the tragedy:"},{"time":1015440,"text":"we're building this infrastructure\nof surveillance authoritarianism"},{"time":1021000,"text":"merely to get people to click on ads."},{"time":1025240,"text":"And this won't be\nOrwell's authoritarianism."},{"time":1027839,"text":"This isn't \"1984.\""},{"time":1029760,"text":"Now, if authoritarianism\nis using overt fear to terrorize us,"},{"time":1034359,"text":"we'll all be scared, but we'll know it,"},{"time":1037280,"text":"we'll hate it and we'll resist it."},{"time":1040880,"text":"But if the people in power\nare using these algorithms"},{"time":1045319,"text":"to quietly watch us,"},{"time":1048720,"text":"to judge us and to nudge us,"},{"time":1051720,"text":"to predict and identify\nthe troublemakers and the rebels,"},{"time":1055920,"text":"to deploy persuasion\narchitectures at scale"},{"time":1059840,"text":"and to manipulate individuals one by one"},{"time":1064000,"text":"using their personal, individual\nweaknesses and vulnerabilities,"},{"time":1070720,"text":"and if they're doing it at scale"},{"time":1074080,"text":"through our private screens"},{"time":1075840,"text":"so that we don't even know"},{"time":1077520,"text":"what our fellow citizens\nand neighbors are seeing,"},{"time":1081560,"text":"that authoritarianism\nwill envelop us like a spider's web"},{"time":1086400,"text":"and we may not even know we're in it."}]},{"cues":[{"time":1090440,"text":"So Facebook's market capitalization"},{"time":1093400,"text":"is approaching half a trillion dollars."},{"time":1096720,"text":"It's because it works great\nas a persuasion architecture."},{"time":1101760,"text":"But the structure of that architecture"},{"time":1104600,"text":"is the same whether you're selling shoes"},{"time":1107840,"text":"or whether you're selling politics."},{"time":1110360,"text":"The algorithms do not know the difference."},{"time":1114240,"text":"The same algorithms set loose upon us"},{"time":1117560,"text":"to make us more pliable for ads"},{"time":1120760,"text":"are also organizing our political,\npersonal and social information flows,"},{"time":1127520,"text":"and that's what's got to change."}]},{"cues":[{"time":1130240,"text":"Now, don't get me wrong,"},{"time":1132560,"text":"we use digital platforms\nbecause they provide us with great value."},{"time":1137120,"text":"I use Facebook to keep in touch\nwith friends and family around the world."},{"time":1142000,"text":"I've written about how crucial\nsocial media is for social movements."},{"time":1147800,"text":"I have studied how\nthese technologies can be used"},{"time":1150840,"text":"to circumvent censorship around the world."},{"time":1155280,"text":"But it's not that the people who run,\nyou know, Facebook or Google"},{"time":1161720,"text":"are maliciously and deliberately trying"},{"time":1164440,"text":"to make the country\nor the world more polarized"},{"time":1168920,"text":"and encourage extremism."},{"time":1171440,"text":"I read the many\nwell-intentioned statements"},{"time":1175440,"text":"that these people put out."},{"time":1179600,"text":"But it's not the intent or the statements\npeople in technology make that matter,"},{"time":1185680,"text":"it's the structures\nand business models they're building."},{"time":1190360,"text":"And that's the core of the problem."},{"time":1192480,"text":"Either Facebook is a giant con\nof half a trillion dollars"},{"time":1198200,"text":"and ads don't work on the site,"},{"time":1200120,"text":"it doesn't work\nas a persuasion architecture,"},{"time":1202840,"text":"or its power of influence\nis of great concern."},{"time":1208560,"text":"It's either one or the other."},{"time":1210360,"text":"It's similar for Google, too."}]},{"cues":[{"time":1212880,"text":"So what can we do?"},{"time":1215360,"text":"This needs to change."},{"time":1217320,"text":"Now, I can't offer a simple recipe,"},{"time":1219920,"text":"because we need to restructure"},{"time":1222200,"text":"the whole way our\ndigital technology operates."},{"time":1225240,"text":"Everything from the way\ntechnology is developed"},{"time":1229360,"text":"to the way the incentives,\neconomic and otherwise,"},{"time":1233240,"text":"are built into the system."},{"time":1236480,"text":"We have to face and try to deal with"},{"time":1239960,"text":"the lack of transparency\ncreated by the proprietary algorithms,"},{"time":1244640,"text":"the structural challenge\nof machine learning's opacity,"},{"time":1248480,"text":"all this indiscriminate data\nthat's being collected about us."},{"time":1253000,"text":"We have a big task in front of us."},{"time":1256160,"text":"We have to mobilize our technology,"},{"time":1259760,"text":"our creativity"},{"time":1261360,"text":"and yes, our politics"},{"time":1264240,"text":"so that we can build\nartificial intelligence"},{"time":1266920,"text":"that supports us in our human goals"},{"time":1270800,"text":"but that is also constrained\nby our human values."},{"time":1275600,"text":"And I understand this won't be easy."},{"time":1278360,"text":"We might not even easily agree\non what those terms mean."},{"time":1282920,"text":"But if we take seriously"},{"time":1286240,"text":"how these systems that we\ndepend on for so much operate,"},{"time":1292240,"text":"I don't see how we can postpone\nthis conversation anymore."},{"time":1297200,"text":"These structures"},{"time":1299760,"text":"are organizing how we function"},{"time":1303880,"text":"and they're controlling"},{"time":1306200,"text":"what we can and we cannot do."},{"time":1308840,"text":"And many of these ad-financed platforms,"},{"time":1311320,"text":"they boast that they're free."},{"time":1312920,"text":"In this context, it means\nthat we are the product that's being sold."},{"time":1318840,"text":"We need a digital economy"},{"time":1321600,"text":"where our data and our attention"},{"time":1325120,"text":"is not for sale to the highest-bidding\nauthoritarian or demagogue."}]},{"cues":[{"time":1331160,"text":"(Applause)"}]},{"cues":[{"time":1338480,"text":"So to go back to\nthat Hollywood paraphrase,"},{"time":1341760,"text":"we do want the prodigious potential"},{"time":1345520,"text":"of artificial intelligence\nand digital technology to blossom,"},{"time":1349400,"text":"but for that, we must face\nthis prodigious menace,"},{"time":1354360,"text":"open-eyed and now."}]},{"cues":[{"time":1356320,"text":"Thank you."}]},{"cues":[{"time":1357560,"text":"(Applause)"}]}]}